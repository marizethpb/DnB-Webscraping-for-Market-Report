{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as condition\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initiating all the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "industry = 'Household Appliances'\n",
    "country = 'China'\n",
    "front_page = 'https://www.dnb.com/business-directory/company-information.medical_equipment_and_supplies_manufacturing.cn.html'\n",
    "companies_in_a_page = 50\n",
    "start_page = 19\n",
    "end_page = 19\n",
    "title_of_front_page = 'Medical Equipment And Supplies Manufacturing Companies In China'\n",
    "maximum_wait_time = 20\n",
    "excel_path = \"c:\\\\Users\\\\Owner\\\\\"  # need to double the \\ from the original path\n",
    "excel_name = country + '_' +  industry + str(start_page) + '-' + str(end_page)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up the browser for web scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will be using Microsoft Edge as the browser\n",
    "driver = webdriver.Edge()\n",
    "\n",
    "# Opening the first page of the webpage\n",
    "driver.get(front_page)\n",
    "\n",
    "# Setting the waiting time \n",
    "wait = WebDriverWait(driver, maximum_wait_time)\n",
    "\n",
    "# Waiting for the title of the front page to appear in the webpage\n",
    "try: \n",
    "    wait.until(\n",
    "        condition.text_to_be_present_in_element(\n",
    "            (\n",
    "                #XPATH for website title\n",
    "                By.XPATH,\n",
    "                ('//*[@id=\"page\"]/div[2]/div/div[1]/div/div/div/div[2]/div/div/div/div'),\n",
    "            ),\n",
    "            title_of_front_page,\n",
    "        ))\n",
    "\n",
    "# Page will refresh after reaching the maximum wait time\n",
    "except TimeoutException: \n",
    "    driver.refresh()\n",
    "\n",
    "# There's always gonna be a cookie notification that will pop up\n",
    "cookies_button = wait.until(\n",
    "    condition.element_to_be_clickable((By.XPATH, '//*[@id=\"truste-consent-button\"]')))\n",
    "\n",
    "# so we will click it\n",
    "cookies_button.click()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The start of the web scraping. We would get all the listed companies in each page together with their respective state, and directory link (will be used to get the full address and website)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists to be used to append the extracted details\n",
    "companies = []\n",
    "broken_pages = []\n",
    "\n",
    "# Looping over desired pages of the user\n",
    "for page in range(start_page, end_page + 1):\n",
    "\n",
    "    # Opening the page\n",
    "    driver.get(front_page + f\"?page={page}\")\n",
    "\n",
    "    # Waiting for the webpage to load\n",
    "    try:\n",
    "        wait.until(\n",
    "            condition.text_to_be_present_in_element(\n",
    "                (\n",
    "                    By.XPATH,\n",
    "                    (\n",
    "                        # XPATH for the title of the page\n",
    "                        '//*[@id=\"page\"]/div[2]/div/div[1]/div/div/div/div[2]/div/div/div/div'\n",
    "                    ),\n",
    "                ),\n",
    "                title_of_front_page,\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    # There's instances that  the internet connection would be too slow and the challenge validation \n",
    "    # won't refresh after 10 secs, so this exception will take care of these cases\n",
    "    except TimeoutException or 'Challenge Validation' in driver.title:\n",
    "        driver.refresh()\n",
    "\n",
    "    # Or rare instances that the page is just broken \n",
    "    # and we will take note of those\n",
    "    except '505 Error' or 'Business Directory' in driver.title:\n",
    "        broken_pages.append(front_page + f\"?page={page}\")\n",
    "        continue\n",
    "\n",
    "    # Extract the needed infos\n",
    "    finally:\n",
    "\n",
    "         # Gathering the necessary datas for each company by looping through each divs which starts at 2\n",
    "        for i in range(2, companies_in_a_page + 2):\n",
    "\n",
    "            # Getting the company name\n",
    "            company = driver.find_element(\n",
    "                By.XPATH, f'//*[@id=\"companyResults\"]/div[{i}]/div[1]/a'\n",
    "            )\n",
    "\n",
    "            # Getting the diretory link \n",
    "            directory_link = driver.find_element(\n",
    "                By.XPATH, f'//*[@id=\"companyResults\"]/div[{i}]/div[1]/a'\n",
    "            )\n",
    "\n",
    "            # Getting the state of where the company is\n",
    "            state = driver.find_element(\n",
    "                By.XPATH, f'//*[@id=\"companyResults\"]/div[{i}]/div[2]'\n",
    "            )\n",
    "\n",
    "            # Appending all those information in companies list\n",
    "            companies.append(\n",
    "                {\n",
    "                    # address and website are left blank because we are only able fill out \n",
    "                    # after looping through the directory links\n",
    "                    \"company\": company.text,\n",
    "                    \"directory_link\": directory_link.get_attribute(\"href\"),\n",
    "                    \"address\": \"\",\n",
    "                    \"state\": state.text.split(\",\")[0].replace(\"Country: \", \"\"),\n",
    "                    \"country\": country,\n",
    "                    \"website\": \"\"\n",
    "                }\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the address and website of the company by going through each of directory links "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of broken links \n",
    "broken_directory_links = []\n",
    "\n",
    "# Looping through directory links to get the address and website\n",
    "for company in companies:\n",
    "    url = company[\"directory_link\"]\n",
    "    driver.get(url)\n",
    "\n",
    "    # Waiting for the page to load\n",
    "    try:\n",
    "        wait.until(\n",
    "            condition.element_to_be_clickable(\n",
    "                # The discover span at the bottom of the page\n",
    "                (By.XPATH, '//*[@id=\"footer_accordion_1_id\"]/span[1]')\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # Refresh the page and wait for discover element at the bottom of the page\n",
    "    # if the page took longer to load\n",
    "    except TimeoutException:\n",
    "        driver.refresh()\n",
    "        wait.until(\n",
    "            condition.element_to_be_clickable(\n",
    "                (By.XPATH, '//*[@id=\"footer_accordion_1_id\"]/span[1]')\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # If the title of the page is Business Directory then the company have no directory page\n",
    "    except \"Business Directory\" in driver.title:\n",
    "        continue\n",
    "\n",
    "    # Getting the full address of the company \n",
    "    try:\n",
    "        address = driver.find_element(\n",
    "            By.XPATH, f'//*[@id=\"company_profile_snapshot\"]/div[3]/div[2]/span/span'\n",
    "        )\n",
    "        # Updating the dictionary and removing the unnecessary text embedded in the element text\n",
    "        company[\"address\"] = address.text.replace(\" See other locations\", \"\")\n",
    "\n",
    "    # There's rarely a case of a company that don't have address but we should catch that too\n",
    "    except NoSuchElementException:\n",
    "        pass\n",
    "    \n",
    "    # Getting the website of the company\n",
    "    try:\n",
    "        website = driver.find_element(\n",
    "            By.XPATH, '//*[@id=\"company_new_header\"]/div/div[2]/div[2]/div[1]/div[2]/a'\n",
    "        )\n",
    "        # Updating the dictionary\n",
    "        company[\"website\"] = website.get_attribute(\"href\")\n",
    "\n",
    "    # There's a lot of cases that there are no recorded sites\n",
    "    except NoSuchElementException:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking a look at the scraped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>directory_link</th>\n",
       "      <th>address</th>\n",
       "      <th>state</th>\n",
       "      <th>country</th>\n",
       "      <th>website</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Beier Taike Medical Instruments Jiangsu Co., Ltd.</td>\n",
       "      <td>https://www.dnb.com/business-directory/company...</td>\n",
       "      <td>Jiangsu Yuma Aluminum Industry Co., Ltd., Erch...</td>\n",
       "      <td>Taizhou</td>\n",
       "      <td>China</td>\n",
       "      <td>http://www.better-tec.com/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Foshan Dihua Technology Co., Ltd.</td>\n",
       "      <td>https://www.dnb.com/business-directory/company...</td>\n",
       "      <td>1F, No.98, South Area, Guojiahuojujihua Foshan...</td>\n",
       "      <td>Foshan</td>\n",
       "      <td>China</td>\n",
       "      <td>http://www.dihua-tech.com/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Shenzhen Chuanshi Biological Medical Co., Ltd.</td>\n",
       "      <td>https://www.dnb.com/business-directory/company...</td>\n",
       "      <td>Floor 4, Building B, Haikexing Zhanlue Xinxing...</td>\n",
       "      <td>Shenzhen</td>\n",
       "      <td>China</td>\n",
       "      <td>http://www.thistory.com.cn/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kunshan Ideaman Intelligent Technology Co., Ltd.</td>\n",
       "      <td>https://www.dnb.com/business-directory/company...</td>\n",
       "      <td>No.591, Shipai Liji Road, Bacheng Town Kunshan...</td>\n",
       "      <td>Kunshan</td>\n",
       "      <td>China</td>\n",
       "      <td>http://www.ksideaman.com/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cixi Bulade Medical Instruments Co., Ltd.</td>\n",
       "      <td>https://www.dnb.com/business-directory/company...</td>\n",
       "      <td>No.60, Kandun W. Street, Kandun Sub-District N...</td>\n",
       "      <td>Ningbo</td>\n",
       "      <td>China</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             company  \\\n",
       "0  Beier Taike Medical Instruments Jiangsu Co., Ltd.   \n",
       "1                  Foshan Dihua Technology Co., Ltd.   \n",
       "2     Shenzhen Chuanshi Biological Medical Co., Ltd.   \n",
       "3   Kunshan Ideaman Intelligent Technology Co., Ltd.   \n",
       "4          Cixi Bulade Medical Instruments Co., Ltd.   \n",
       "\n",
       "                                      directory_link  \\\n",
       "0  https://www.dnb.com/business-directory/company...   \n",
       "1  https://www.dnb.com/business-directory/company...   \n",
       "2  https://www.dnb.com/business-directory/company...   \n",
       "3  https://www.dnb.com/business-directory/company...   \n",
       "4  https://www.dnb.com/business-directory/company...   \n",
       "\n",
       "                                             address     state country  \\\n",
       "0  Jiangsu Yuma Aluminum Industry Co., Ltd., Erch...   Taizhou   China   \n",
       "1  1F, No.98, South Area, Guojiahuojujihua Foshan...    Foshan   China   \n",
       "2  Floor 4, Building B, Haikexing Zhanlue Xinxing...  Shenzhen   China   \n",
       "3  No.591, Shipai Liji Road, Bacheng Town Kunshan...   Kunshan   China   \n",
       "4  No.60, Kandun W. Street, Kandun Sub-District N...    Ningbo   China   \n",
       "\n",
       "                       website  \n",
       "0   http://www.better-tec.com/  \n",
       "1   http://www.dihua-tech.com/  \n",
       "2  http://www.thistory.com.cn/  \n",
       "3    http://www.ksideaman.com/  \n",
       "4                               "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Putting dictionary on DataFrame so we can export it to excel and have a better view\n",
    "companies_df = pd.DataFrame(data = companies)\n",
    "\n",
    "# We don't need the index\n",
    "companies_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# First 5 rows will suffice\n",
    "companies_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding a column because we need this as input to advance search in DnB Finance Analytics, the platform which we will get the number of phone number, line of business, number of employees, and annual sales of the company."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>directory_link</th>\n",
       "      <th>address</th>\n",
       "      <th>state</th>\n",
       "      <th>country</th>\n",
       "      <th>website</th>\n",
       "      <th>first3_address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Beier Taike Medical Instruments Jiangsu Co., Ltd.</td>\n",
       "      <td>https://www.dnb.com/business-directory/company...</td>\n",
       "      <td>Jiangsu Yuma Aluminum Industry Co., Ltd., Erch...</td>\n",
       "      <td>Taizhou</td>\n",
       "      <td>China</td>\n",
       "      <td>http://www.better-tec.com/</td>\n",
       "      <td>Jiangsu Yuma Aluminum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Foshan Dihua Technology Co., Ltd.</td>\n",
       "      <td>https://www.dnb.com/business-directory/company...</td>\n",
       "      <td>1F, No.98, South Area, Guojiahuojujihua Foshan...</td>\n",
       "      <td>Foshan</td>\n",
       "      <td>China</td>\n",
       "      <td>http://www.dihua-tech.com/</td>\n",
       "      <td>1F, No.98, South</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Shenzhen Chuanshi Biological Medical Co., Ltd.</td>\n",
       "      <td>https://www.dnb.com/business-directory/company...</td>\n",
       "      <td>Floor 4, Building B, Haikexing Zhanlue Xinxing...</td>\n",
       "      <td>Shenzhen</td>\n",
       "      <td>China</td>\n",
       "      <td>http://www.thistory.com.cn/</td>\n",
       "      <td>Floor 4, Building</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kunshan Ideaman Intelligent Technology Co., Ltd.</td>\n",
       "      <td>https://www.dnb.com/business-directory/company...</td>\n",
       "      <td>No.591, Shipai Liji Road, Bacheng Town Kunshan...</td>\n",
       "      <td>Kunshan</td>\n",
       "      <td>China</td>\n",
       "      <td>http://www.ksideaman.com/</td>\n",
       "      <td>No.591, Shipai Liji</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cixi Bulade Medical Instruments Co., Ltd.</td>\n",
       "      <td>https://www.dnb.com/business-directory/company...</td>\n",
       "      <td>No.60, Kandun W. Street, Kandun Sub-District N...</td>\n",
       "      <td>Ningbo</td>\n",
       "      <td>China</td>\n",
       "      <td></td>\n",
       "      <td>No.60, Kandun W.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             company  \\\n",
       "0  Beier Taike Medical Instruments Jiangsu Co., Ltd.   \n",
       "1                  Foshan Dihua Technology Co., Ltd.   \n",
       "2     Shenzhen Chuanshi Biological Medical Co., Ltd.   \n",
       "3   Kunshan Ideaman Intelligent Technology Co., Ltd.   \n",
       "4          Cixi Bulade Medical Instruments Co., Ltd.   \n",
       "\n",
       "                                      directory_link  \\\n",
       "0  https://www.dnb.com/business-directory/company...   \n",
       "1  https://www.dnb.com/business-directory/company...   \n",
       "2  https://www.dnb.com/business-directory/company...   \n",
       "3  https://www.dnb.com/business-directory/company...   \n",
       "4  https://www.dnb.com/business-directory/company...   \n",
       "\n",
       "                                             address     state country  \\\n",
       "0  Jiangsu Yuma Aluminum Industry Co., Ltd., Erch...   Taizhou   China   \n",
       "1  1F, No.98, South Area, Guojiahuojujihua Foshan...    Foshan   China   \n",
       "2  Floor 4, Building B, Haikexing Zhanlue Xinxing...  Shenzhen   China   \n",
       "3  No.591, Shipai Liji Road, Bacheng Town Kunshan...   Kunshan   China   \n",
       "4  No.60, Kandun W. Street, Kandun Sub-District N...    Ningbo   China   \n",
       "\n",
       "                       website         first3_address  \n",
       "0   http://www.better-tec.com/  Jiangsu Yuma Aluminum  \n",
       "1   http://www.dihua-tech.com/       1F, No.98, South  \n",
       "2  http://www.thistory.com.cn/      Floor 4, Building  \n",
       "3    http://www.ksideaman.com/    No.591, Shipai Liji  \n",
       "4                                    No.60, Kandun W.  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "companies_df[\"first3_address\"] = companies_df[\"address\"].apply(\n",
    "    lambda x: ((\"Pass\" if len(\" \") >= 3 else \" \".join(x.split(\" \")[:3])))\n",
    ")\n",
    "companies_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would also include record these broken link in Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Broken Pages in Directory</th>\n",
       "      <th>Broken Links in Directory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Broken Pages in Directory, Broken Links in Directory]\n",
       "Index: []"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Putting dictionary on DataFrame so we can export it to excel and have a better view\n",
    "broken_df = pd.DataFrame(\n",
    "    {\n",
    "        \"Broken Pages in Directory\": broken_pages,\n",
    "        \"Broken Links in Directory\": broken_directory_links,\n",
    "    }\n",
    ")\n",
    "# We don't need the index\n",
    "broken_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# First 5 rows will suffice\n",
    "broken_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exporting the Data frames to Excel. The resulting Excel file will have 2 sheets : Scrape Data and Broken (Pages and Links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an Excel file to write the results to\n",
    "output_file = excel_path + excel_name + \".xlsx\"\n",
    "\n",
    "# Writing the Data Frames to Excel\n",
    "writer = pd.ExcelWriter(output_file, engine= 'openpyxl')\n",
    "\n",
    "# First sheet is alloted for the Scraped Data\n",
    "companies_df.to_excel(writer,sheet_name = 'Scraped Data')\n",
    "\n",
    "# The second sheet if for the list of broken pages and links\n",
    "broken_df.to_excel(writer,sheet_name = 'Broken')\n",
    "\n",
    "# Saving  and Closing the sheet\n",
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
